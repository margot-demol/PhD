Warning: no access to tty (Bad file descriptor).
Thus no job control in this shell.
Thu Apr 28 11:02:48 GMT 2022
jlab.py:30: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  elif dashinfo is not '0':
jlab.py:33: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if dashinfo is not '0':
Fail to get yarn configuration. {"type":"error","data":"An unexpected error occurred: \"ENOENT: no such file or directory, open '/home1/.yarnrc'\"."}
{"type":"info","data":"If you think this is a bug, please open a bug report with the information provided in \"/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/jupyterlab/yarn-error.log\"."}
{"type":"info","data":"Visit https://yarnpkg.com/en/docs/cli/config for documentation about this command."}

[I 2022-04-28 11:03:07.537 ServerApp] jupyterlab | extension was successfully linked.
[W 2022-04-28 11:03:07.548 NotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2022-04-28 11:03:07.555 ServerApp] nbclassic | extension was successfully linked.
[I 2022-04-28 11:03:11.384 ServerApp] notebook_shim | extension was successfully linked.
[I 2022-04-28 11:03:12.010 ServerApp] notebook_shim | extension was successfully loaded.
[I 2022-04-28 11:03:12.011 LabApp] JupyterLab extension loaded from /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/jupyterlab
[I 2022-04-28 11:03:12.011 LabApp] JupyterLab application directory is /home1/datahome/mdemol/.miniconda3/envs/m2env/share/jupyter/lab
[I 2022-04-28 11:03:12.015 ServerApp] jupyterlab | extension was successfully loaded.
[I 2022-04-28 11:03:12.095 ServerApp] nbclassic | extension was successfully loaded.
[I 2022-04-28 11:03:12.095 ServerApp] Serving notebooks from local directory: /home1/datahome/mdemol
[I 2022-04-28 11:03:12.095 ServerApp] Jupyter Server 1.16.0 is running at:
[I 2022-04-28 11:03:12.095 ServerApp] http://r1i0n19:8877/lab
[I 2022-04-28 11:03:12.095 ServerApp]  or http://127.0.0.1:8877/lab
[I 2022-04-28 11:03:12.095 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2022-04-28 11:08:09.905 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:10:53.893 ServerApp] Saving file at /m2_2022/m2lib22/box.py
[I 2022-04-28 11:11:11.647 ServerApp] Saving file at /m2_2022/m2lib22/box.py
[I 2022-04-28 11:14:10.488 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:16:10.799 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:18:11.131 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:20:11.450 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:21:55.776 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:21:59.497 ServerApp] Kernel started: da2870ff-d5a4-449d-90aa-db070ea073bf
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 2e4beaaf-0c92-4d78-b28f-49b46d49ac81
[I 2022-04-28 11:23:56.175 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:24:44.713 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:26:44.996 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:29:19.654 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 11:29:19.659 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 11:29:19.667 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cc191da3-757d-4d8e-84ee-ed6fb5f89cf6
[I 2022-04-28 11:30:45.279 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:32:45.526 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:34:45.820 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:36:46.074 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:37:21.445 ServerApp] Saving file at /m2_2022/m2lib22/box.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-04-28 11:37:28.224 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 11:37:28.234 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 11:37:28.241 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4acbcfe8-7d97-428e-b396-24da37691086
[I 2022-04-28 11:38:46.333 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:40:02.017 ServerApp] Saving file at /m2_2022/m2lib22/box.py
[I 2022-04-28 11:40:15.593 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 11:40:15.599 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 11:40:15.613 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 8490292c-a689-430c-a015-08182fd43360
[I 2022-04-28 11:40:46.597 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:42:46.931 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:44:47.241 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:46:47.556 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:48:47.885 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:50:48.245 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 11:58:48.701 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:02:49.117 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:04:49.483 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:06:49.852 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:08:50.338 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:10:50.722 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:12:51.048 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-04-28 12:13:22.325 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 12:13:22.332 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 12:13:22.348 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: b99c8ba3-7334-48d5-9b75-308f8d48bb73
[I 2022-04-28 12:14:51.412 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:16:51.652 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:18:51.909 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:20:52.210 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:58842
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:58842 after 10 s
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36818
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:36818 after 10 s
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36818
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:36818 after 10 s
[I 2022-04-28 12:22:52.587 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.69 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.63 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 84% memory usage. Resuming worker. Process memory: 10.60 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.63 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 84% memory usage. Resuming worker. Process memory: 10.62 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.68 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.65 GiB -- Worker memory limit: 12.50 GiB
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.66 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 84% memory usage. Resuming worker. Process memory: 10.62 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 10.83 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.63 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 84% memory usage. Resuming worker. Process memory: 10.62 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.64 GiB -- Worker memory limit: 12.50 GiB
distributed.worker_memory - WARNING - Worker is at 84% memory usage. Resuming worker. Process memory: 10.62 GiB -- Worker memory limit: 12.50 GiB
[I 2022-04-28 12:24:52.905 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:26:53.197 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:28:53.511 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
distributed.worker_memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 10.63 GiB -- Worker memory limit: 12.50 GiB
[I 2022-04-28 12:31:08.825 ServerApp] Kernel interrupted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 12:31:09.882 ServerApp] Kernel interrupted: da2870ff-d5a4-449d-90aa-db070ea073bf
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-04-28 12:31:48.626 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 12:31:48.633 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 12:31:48.641 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4b75563d-23bd-4481-9ebe-3bcb598ccdea
[I 2022-04-28 12:32:53.816 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:33:38.018 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 12:33:38.022 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 12:33:38.029 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: bc3ae5e2-f7f5-4775-a648-37e5cff39fe5
[I 2022-04-28 12:34:54.129 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:36:54.470 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:37:00.097 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 12:37:00.102 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 12:37:00.118 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4f4b3ea8-1371-4ad8-99b6-b342689af49d
[I 2022-04-28 12:38:54.764 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:40:55.038 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:42:55.408 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:44:55.780 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:46:56.072 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:48:56.356 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:50:56.646 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:52:56.895 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:54:57.137 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:56:57.469 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 12:58:57.716 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:00:57.953 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:02:58.233 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:04:58.540 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:06:58.777 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:08:59.021 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:10:59.306 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:12:59.651 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:14:59.909 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:17:00.190 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:19:00.472 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:21:00.761 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:21:39.389 ServerApp] Kernel interrupted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 13:21:41.020 ServerApp] Kernel interrupted: da2870ff-d5a4-449d-90aa-db070ea073bf
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1823, in _run_once
    event_list = self._selector.select(timeout)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/selectors.py", line 468, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
KeyboardInterrupt
[I 2022-04-28 13:22:20.637 ServerApp] Saving file at /m2_2022/m2lib22/box.py
[I 2022-04-28 13:23:01.174 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:24:20.658 ServerApp] Saving file at /m2_2022/m2lib22/box.py
[I 2022-04-28 13:25:01.415 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:27:01.688 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:29:01.933 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:31:02.151 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:33:02.416 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:34:15.475 ServerApp] Kernel restarted: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 13:34:15.481 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 13:34:15.495 ServerApp] Restoring connection for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: eb61a581-a7a8-42ee-9d4e-555906f5c878
[I 2022-04-28 13:35:02.651 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:37:02.997 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:43:03.263 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:45:04.351 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:47:04.651 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:49:04.989 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:51:05.257 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:53:05.508 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:55:05.737 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:57:05.967 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 13:59:06.150 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 14:03:23.897 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:03:44.423 ServerApp] Kernel started: 4649914e-ff9c-4151-8330-f3708fc566b6
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 86b20c0a-87cb-40c2-94a2-3d0efc8756c9
[I 2022-04-28 14:03:48.028 ServerApp] Kernel restarted: 4649914e-ff9c-4151-8330-f3708fc566b6
[I 2022-04-28 14:03:48.034 ServerApp] Starting buffering for 4649914e-ff9c-4151-8330-f3708fc566b6:4d7473fc-47ab-4c8f-9219-42a518d6d7f4
[I 2022-04-28 14:03:48.041 ServerApp] Restoring connection for 4649914e-ff9c-4151-8330-f3708fc566b6:4d7473fc-47ab-4c8f-9219-42a518d6d7f4
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 9c7a7cae-504c-4e74-8a9d-5cc7bffd7866
[I 2022-04-28 14:05:24.191 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:07:24.407 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:09:24.675 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:11:24.981 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:13:25.242 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:15:25.540 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:19:25.835 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:21:26.153 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:23:26.458 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:25:26.733 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:27:27.040 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:29:27.308 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:31:27.577 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:33:27.880 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:35:28.155 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:37:28.513 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:39:28.811 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:41:06.493 ServerApp] Saving file at /m2_2022/sandbox/statistics_severalncfiles.ipynb
[I 2022-04-28 14:41:29.273 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:43:29.665 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:45:30.012 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:47:30.311 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:49:30.633 ServerApp] Saving file at /m2_2022/sandbox/statistics_1ncfiles.ipynb
[I 2022-04-28 14:51:32.981 ServerApp] Starting buffering for da2870ff-d5a4-449d-90aa-db070ea073bf:4c3b095f-e284-4bbb-b940-e20323f6ef63
[I 2022-04-28 14:51:32.982 ServerApp] Starting buffering for 4649914e-ff9c-4151-8330-f3708fc566b6:4d7473fc-47ab-4c8f-9219-42a518d6d7f4
[C 2022-04-28 14:52:17.527 ServerApp] received signal 15, stopping
Terminated
[I 2022-04-28 14:52:17.694 ServerApp] Shutting down 3 extensions
[I 2022-04-28 14:52:17.694 ServerApp] Shutting down 2 kernels
[I 2022-04-28 14:52:17.694 ServerApp] Kernel shutdown: da2870ff-d5a4-449d-90aa-db070ea073bf
[I 2022-04-28 14:52:17.695 ServerApp] Kernel shutdown: 4649914e-ff9c-4151-8330-f3708fc566b6
[I 2022-04-28 14:52:20.312 ServerApp] Shutting down 0 terminals
