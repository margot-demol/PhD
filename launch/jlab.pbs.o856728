Warning: no access to tty (Bad file descriptor).
Thus no job control in this shell.
Fri Jul  1 07:14:24 GMT 2022
jlab.py:30: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  elif dashinfo is not '0':
jlab.py:33: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if dashinfo is not '0':
Fail to get yarn configuration. {"type":"error","data":"An unexpected error occurred: \"ENOENT: no such file or directory, open '/home1/.yarnrc'\"."}
{"type":"info","data":"If you think this is a bug, please open a bug report with the information provided in \"/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/jupyterlab/yarn-error.log\"."}
{"type":"info","data":"Visit https://yarnpkg.com/en/docs/cli/config for documentation about this command."}

[I 2022-07-01 07:14:55.320 ServerApp] jupyterlab | extension was successfully linked.
[W 2022-07-01 07:14:55.346 NotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2022-07-01 07:14:55.353 ServerApp] nbclassic | extension was successfully linked.
[I 2022-07-01 07:15:01.196 ServerApp] notebook_shim | extension was successfully linked.
[I 2022-07-01 07:15:01.834 ServerApp] notebook_shim | extension was successfully loaded.
[I 2022-07-01 07:15:01.835 LabApp] JupyterLab extension loaded from /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/jupyterlab
[I 2022-07-01 07:15:01.835 LabApp] JupyterLab application directory is /home1/datahome/mdemol/.miniconda3/envs/m2env/share/jupyter/lab
[I 2022-07-01 07:15:01.839 ServerApp] jupyterlab | extension was successfully loaded.
[I 2022-07-01 07:15:02.008 ServerApp] nbclassic | extension was successfully loaded.
[I 2022-07-01 07:15:02.008 ServerApp] Serving notebooks from local directory: /home1/datahome/mdemol
[I 2022-07-01 07:15:02.008 ServerApp] Jupyter Server 1.16.0 is running at:
[I 2022-07-01 07:15:02.008 ServerApp] http://r1i3n32:8877/lab
[I 2022-07-01 07:15:02.008 ServerApp]  or http://127.0.0.1:8877/lab
[I 2022-07-01 07:15:02.009 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2022-07-01 07:17:34.948 LabApp] Build is up to date
[W 2022-07-01 07:17:41.650 ServerApp] Notebook m2_2022/sandbox/test_aviso_lib.ipynb is not trusted
[I 2022-07-01 07:17:44.820 ServerApp] Kernel started: ef75afff-2fe6-4bdb-85e0-f8941f037171
[I 2022-07-01 07:17:44.822 ServerApp] Kernel started: 0910d410-1877-4b92-9c57-96057a0eecfc
[I 2022-07-01 07:17:44.824 ServerApp] Kernel started: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 07:17:45.595 ServerApp] Kernel started: 2858f50d-722a-486d-acb6-524de679a197
[I 2022-07-01 07:17:45.681 ServerApp] Kernel started: e42f0f13-06eb-482f-9f32-3548713185ab
[I 2022-07-01 07:17:45.708 ServerApp] Kernel started: 9cf90e35-4179-438f-aa8a-9f3bd6af8d35
readline: /etc/inputrc: line 19: term: unknown variable name
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 42aa2658-cf96-4c10-b0a5-09667185fc40
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 48bb7719-0436-402f-b3c9-a3f050497fc7
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 38b17046-8d3d-4561-99e6-d58e5eee836f
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e0d8c3d1-fcd5-40b4-903b-7b0b46e50364
readline: /etc/inputrc: line 19: term: unknown variable name
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 9c16eaa7-8888-4f99-b225-ddf05a4c1d62
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 638a61a0-14eb-49ec-b8e0-552dd9dc7597
[I 2022-07-01 07:19:05.266 ServerApp] Kernel interrupted: 0910d410-1877-4b92-9c57-96057a0eecfc
[I 2022-07-01 07:19:05.963 ServerApp] Kernel interrupted: 0910d410-1877-4b92-9c57-96057a0eecfc
[I 2022-07-01 07:19:41.840 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:19:42.605 ServerApp] Saving file at /m2_2022/sandbox/diag_overview.ipynb
[I 2022-07-01 07:20:47.554 ServerApp] Starting buffering for 2858f50d-722a-486d-acb6-524de679a197:87f419aa-bb38-4b3e-ab9d-d7cb47f1b194
[I 2022-07-01 07:20:54.649 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:3e754a6c-451b-48b0-83ad-1db7403f12e4
[I 2022-07-01 07:21:42.662 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:23:42.940 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:25:43.225 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:27:43.499 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:29:19.899 ServerApp] Saving file at /m2_2022/m2lib22/aviso.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 07:29:38.019 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 07:29:38.026 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 07:29:38.042 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[I 2022-07-01 07:29:43.784 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 9ec6ac13-b801-49fe-8a29-d15b0532c2e5
[I 2022-07-01 07:31:44.106 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:33:44.382 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:35:44.662 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:37:44.943 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:38:39.415 ServerApp] Saving file at /m2_2022/m2lib22/aviso.py
[I 2022-07-01 07:39:28.064 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:a4ef6f7b-9e63-48aa-877e-22c3b9c89b0a
[I 2022-07-01 07:39:38.628 ServerApp] Kernel started: 133cb437-381c-4f16-818b-45576f715f12
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: d01bf909-2345-4424-89fc-9307603e3712
[I 2022-07-01 07:39:45.228 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:41:45.486 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:43:45.769 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 07:44:05.623 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 07:44:05.641 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 07:44:05.673 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 074eda83-f72b-4028-8f27-996091848c48
[I 2022-07-01 07:45:46.043 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:47:46.318 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:49:46.600 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:51:46.877 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:53:47.158 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:55:47.513 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:57:47.821 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 07:59:48.144 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:03:48.439 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:05:48.708 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:06:39.396 ServerApp] Saving file at /m2_2022/m2lib22/aviso.py
[I 2022-07-01 08:08:39.419 ServerApp] Saving file at /m2_2022/m2lib22/aviso.py
[I 2022-07-01 08:10:17.659 ServerApp] Saving file at /m2_2022/m2lib22/aviso.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 08:11:17.315 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 199, in <module>
    from ._cythonized_array_utils import *
  File "<frozen importlib._bootstrap>", line 389, in parent
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2[I 2022-07-01 08:11:17.564 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 199, in <module>
    from ._cythonized_array_utils import *
  File "<frozen importlib._bootstrap>", line 389, in parent
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 199, in <module>
    from ._cythonized_array_utils import *
  File "<frozen importlib._bootstrap>", line 389, in parent
KeyboardInterrupt
Exception ignored in: <bound method GCDiagnosis._gc_callback of <distributed.utils_perf.GCDiagnosis object at 0x2aaab631e400>>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_perf.py", line 177, in _gc_callback
    def _gc_callback(self, phase, info):
KeyboardInterrupt: 
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 198, in <module>
    from ._misc import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/_misc.py", line 4, in <module>
    from .lapack import get_lapack_funcs
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1033, in get_data
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 198, in <module>
    from ._misc import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/_misc.py", line 4, in <module>
    from .lapack import get_lapack_funcs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/lapack.py", line 818, in <module>
    from scipy.linalg import _flapack
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 198, in <module>
    from ._misc import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/_misc.py", line 4, in <module>
    from .lapack import get_lapack_funcs
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1032, in get_data
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 8, in <module>
    from scipy.fft import _pocketfft
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/__init__.py", line 90, in <module>
    from ._fftlog import fht, ifht, fhtoffset
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fft/_fftlog.py", line 11, in <module>
    from ..special import loggamma, poch
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/__init__.py", line 652, in <module>
    from . import _basic
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_basic.py", line 16, in <module>
    from . import _orthogonal
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/__init__.py", line 198, in <module>
    from ._misc import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/linalg/_misc.py", line 4, in <module>
    from .lapack import get_lapack_funcs
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1032, in get_data
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/fft.py", line 8, in <module>
    import scipy.fftpack
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/__init__.py", line 94, in <module>
    from ._basic import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/scipy/fftpack/_basic.py", line 9, in <module>
    from ._helper import _good_shape
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 934, in get_code
  File "<frozen importlib._bootstrap_external>", line 1033, in get_data
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 08:11:36.988 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 08:11:36.992 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 08:11:37.000 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 161daabd-6201-4868-86a9-4e62edb9870d
[I 2022-07-01 08:11:49.041 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:13:49.498 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:15:49.766 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:17:50.026 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:19:50.263 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:21:50.494 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:23:50.805 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:25:51.106 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:27:51.489 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:31:51.763 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:33:27.580 ServerApp] Saving file at /m2_2022/m2lib22/stress_to_windterm.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 08:33:45.359 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 08:33:45.365 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 08:33:45.382 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[I 2022-07-01 08:33:52.069 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 990c975a-226b-46bd-8ebe-52ab19add690
[I 2022-07-01 08:35:52.480 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:37:53.695 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:39:53.916 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:41:54.287 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:43:54.634 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:47:54.951 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:49:55.263 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:51:55.538 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:53:55.844 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:55:56.135 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:57:56.431 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 08:59:56.775 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:01:57.093 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:03:57.459 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:05:57.802 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:07:58.077 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:09:58.420 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:10:08.457 ServerApp] Saving file at /m2_2022/m2lib22/erastar.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:10:30.108 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 09:10:30.113 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 09:10:30.133 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cdac0b3a-d334-41db-876d-81bc783617bb
[I 2022-07-01 09:11:58.728 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:13:59.043 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:14:22.581 ServerApp] Saving file at /m2_2022/m2lib22/stress_to_windterm.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:14:43.859 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 09:14:43.864 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 09:14:43.884 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: d7e6c045-7fcb-4180-b41b-ff60c9551d7f
[I 2022-07-01 09:15:06.753 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2095, in find_on_path
    factory = dist_factory(path_item, entry, only)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2106, in dist_factory
    os.path.isdir(os.path.join(path_item, entry))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/genericpath.py", line 45, in isdir
    return stat.S_ISDIR(st.st_mode)
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
Process Dask Worker process (from Nanny):
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/process.py", line 175, in _run
    target(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 918, in _run
    loop.run_sync(do_stop)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 688, in <lambda>
    lambda f: self._run_callback(functools.partial(callback, future))
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/nanny.py", line 911, in _run
    loop.run_sync(run)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/ioloop.py", line 524, in run_sync
    self.start()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/platform/asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 570, in run_forever
    self._run_once()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/base_events.py", line 1859, in _run_once
    handle._run()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 1178, in handle_scheduler
    await self.handle_stream(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 606, in handle_stream
    msgs = await comm.read()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/tcp.py", line 252, in read
    msg = await from_frames(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 98, in from_frames
    res = _from_frames()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/utils.py", line 81, in _from_frames
    return protocol.loads(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 167, in loads
    return msgpack.loads(
  File "msgpack/_unpacker.pyx", line 194, in msgpack._cmsgpack.unpackb
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/core.py", line 147, in _decode_default
    return merge_and_deserialize(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 488, in merge_and_deserialize
    return deserialize(header, merged_frames, deserializers=deserializers)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 417, in deserialize
    return loads(header, frames)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/serialize.py", line 96, in pickle_loads
    return pickle.loads(x, buffers=new)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/protocol/pickle.py", line 66, in loads
    return pickle.loads(x)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/__init__.py", line 1, in <module>
    from . import testing, tutorial, ufuncs
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/testing.py", line 8, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/duck_array_ops.py", line 24, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/dask_array_compat.py", line 6, in <module>
    from .pycompat import dask_version
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 46, in <module>
    dsk = DuckArrayModule("dask")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/xarray/core/pycompat.py", line 25, in __init__
    duck_array_type = (import_module("dask.array").Array,)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/__init__.py", line 2, in <module>
    from dask.array import backends, fft, lib, linalg, ma, overlap, random
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/backends.py", line 13, in <module>
    from dask.array.percentile import _percentile
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/percentile.py", line 9, in <module>
    from dask.array.core import Array
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/core.py", line 38, in <module>
    from dask.array.chunk_types import is_valid_array_chunk, is_valid_chunk_type
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/dask/array/chunk_types.py", line 122, in <module>
    import sparse
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/__init__.py", line 1, in <module>
    from ._coo import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/__init__.py", line 1, in <module>
    from .core import COO, as_coo
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/sparse/_coo/core.py", line 9, in <module>
    import numba
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/__init__.py", line 19, in <module>
    from numba.core import config
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/numba/core/config.py", line 15, in <module>
    import llvmlite.binding as ll
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/__init__.py", line 4, in <module>
    from .dylib import *
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/dylib.py", line 3, in <module>
    from llvmlite.binding import ffi
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/llvmlite/binding/ffi.py", line 175, in <module>
    from pkg_resources import resource_filename
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3260, in <module>
    def _initialize_master_working_set():
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3234, in _call_aside
    f(*args, **kwargs)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 3272, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 572, in _build_master
    ws = cls()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 565, in __init__
    self.add_entry(entry)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 621, in add_entry
    for dist in find_distributions(entry, True):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2096, in find_on_path
    for dist in factory(fullpath):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/pkg_resources/__init__.py", line 2154, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
KeyboardInterrupt
[I 2022-07-01 09:15:09.434 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:15:44.344 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 09:15:44.349 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 09:15:44.369 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[I 2022-07-01 09:15:59.360 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e55e5cbe-4649-465c-a939-ded11032df0c
[I 2022-07-01 09:17:59.675 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:20:00.053 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:22:01.524 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:24:01.876 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:26:02.179 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:27:04.389 ServerApp] Saving file at /m2_2022/m2lib22/stress_to_windterm.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:27:22.260 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 09:27:22.266 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 09:27:22.286 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 084cebc2-e5ea-402f-a4f9-b249bc7ef612
[I 2022-07-01 09:28:02.490 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:29:22.288 ServerApp] Saving file at /m2_2022/m2lib22/stress_to_windterm.py
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:29:40.120 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 09:29:40.124 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 09:29:40.139 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: bd0261cc-a949-44f4-9792-f6371dd135c7
[I 2022-07-01 09:30:03.784 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:30:03.784 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:32:04.351 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:32:04.352 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:34:04.543 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:34:04.544 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:36:04.784 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:36:04.785 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:38:05.011 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:38:05.012 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:40:05.238 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:40:05.239 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:42:05.491 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:42:05.492 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:43:36.517 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 09:44:05.793 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:44:05.795 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:46:06.086 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:46:06.086 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:48:06.390 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:48:06.390 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:50:06.700 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 09:50:06.701 ServerApp] Notebook m2_2022/sandbox/diag_one_obs.ipynb is not trusted
[I 2022-07-01 09:52:06.946 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:54:07.247 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:56:07.530 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 09:58:07.851 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 10:00:08.234 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 10:02:08.581 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 10:04:09.239 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 10:06:09.525 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 10:08:09.942 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 10:10:59.182 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 10:10:59.183 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 10:10:59.252 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 10:11:04.185 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 10:11:04.253 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[W 2022-07-01 10:11:09.713 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 10:11:10.140 ServerApp] WebSocket ping timeout after 119997 ms.
[I 2022-07-01 10:11:14.714 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:ff3d1dad-34e3-4e5c-a8a1-3d9ebfab0197
[I 2022-07-01 10:11:15.141 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 11:08:10.111 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:ff3d1dad-34e3-4e5c-a8a1-3d9ebfab0197
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: f49a4806-e9a0-4118-a95f-b38d919f27db
[I 2022-07-01 11:08:12.696 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: b075080d-3f94-445f-b1c4-fd0f1d65f49f
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 79b6e28d-7ca5-482d-8a6a-d8da7f8627ab
[I 2022-07-01 11:08:24.263 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 76997b98-87f4-432d-b353-4fdd05e9fe59
[W 2022-07-01 11:08:32.985 ServerApp] delete /m2_2022/sandbox/dask-worker.o850445
[W 2022-07-01 11:08:33.146 ServerApp] delete /m2_2022/sandbox/dask-worker.o850446
[W 2022-07-01 11:08:33.150 ServerApp] delete /m2_2022/sandbox/dask-worker.o850447
[W 2022-07-01 11:08:33.152 ServerApp] delete /m2_2022/sandbox/dask-worker.o850448
[W 2022-07-01 11:08:33.155 ServerApp] delete /m2_2022/sandbox/dask-worker.o850449
[W 2022-07-01 11:08:33.157 ServerApp] delete /m2_2022/sandbox/dask-worker.o850512
[W 2022-07-01 11:08:33.161 ServerApp] delete /m2_2022/sandbox/dask-worker.o851322
[I 2022-07-01 11:09:11.848 ServerApp] Kernel started: 02ab2603-3f95-4942-86fb-59306979415e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: ed6ffa41-763b-4804-bfce-4e7502605140
[I 2022-07-01 11:11:11.454 ServerApp] Saving file at /m2_2022/sandbox/animation.ipynb
[I 2022-07-01 11:11:28.417 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:12:45.100 ServerApp] Creating new directory in /m2_2022/sandbox
[I 2022-07-01 11:13:28.847 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:15:29.266 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:17:29.693 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:19:30.120 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:21:30.604 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:24:23.876 ServerApp] Creating new directory in /m2_2022
[I 2022-07-01 11:25:31.031 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 11:25:32.646 ServerApp] delete /m2_2022/sandbox/images
[I 2022-07-01 11:27:31.402 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 11:28:22.668 ServerApp] delete /m2_2022/images/labels6_iobs435.png
[I 2022-07-01 11:29:31.744 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:31:32.162 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:33:33.282 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:39:33.751 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:41:34.315 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:43:34.790 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:45:35.264 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:47:35.714 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:49:36.247 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:51:36.818 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 11:51:57.674 ServerApp] delete /m2_2022/images/labels6_iobs435.gif
[W 2022-07-01 11:53:17.016 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 11:53:37.195 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 11:54:36.631 ServerApp] delete /m2_2022/images/labels6_iobs435.gif
[I 2022-07-01 11:55:37.587 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 11:57:38.053 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 11:59:38.385 ServerApp] delete /m2_2022/sandbox/labels6_iobs435.gif
[I 2022-07-01 11:59:38.632 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:01:39.039 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:03:39.422 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:05:39.968 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:07:22.754 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:07:40.371 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:09:40.795 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:11:41.280 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:13:35.983 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 12:13:41.698 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:13:47.130 ServerApp] delete /m2_2022/images/labels6_iobs435
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:57379
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:57379 after 10 s
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40571
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:40571 after 10 s
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:56788
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:56788 after 10 s
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40757
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 326, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 501, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 2949, in gather_dep
    response = await get_data_from_worker(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4173, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 386, in retry_operation
    return await retry(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/utils_comm.py", line 371, in retry
    return await coro()
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/worker.py", line 4150, in _get_data
    comm = await rpc.connect(worker)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1146, in connect
    return await connect_attempt
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/core.py", line 1082, in _connect
    comm = await connect(
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/distributed/comm/core.py", line 331, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://127.0.0.1:40757 after 10 s
[I 2022-07-01 12:14:20.981 ServerApp] Kernel restarted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 12:14:20.988 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 12:14:21.010 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 3633ddee-4db3-432f-80b4-0370a0b6aa9f
[I 2022-07-01 12:15:42.288 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:17:16.348 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:17:42.514 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:19:42.779 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:20:48.505 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:21:43.046 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:23:26.419 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:23:43.263 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:25:20.743 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:25:43.426 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:27:43.686 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:28:33.692 ServerApp] Kernel started: 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 1cc3973b-d5aa-4074-bbcc-1f513dd29b8e
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 9dd9377a-43bd-4617-bc74-db4b8a09def7
[I 2022-07-01 12:29:31.109 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 12:29:31.944 ServerApp] Kernel interrupted: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
[I 2022-07-01 12:29:43.944 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:29:47.352 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:31:44.825 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:33:45.065 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:35:09.552 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:35:45.282 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:37:45.596 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:39:45.898 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:39:59.639 ServerApp] Starting buffering for 02ab2603-3f95-4942-86fb-59306979415e:eb476715-9f83-47fd-9cc7-0699a9656e6a
[I 2022-07-01 12:41:46.216 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:43:05.729 ServerApp] delete /m2_2022/images/labels6_iobs435
[I 2022-07-01 12:43:46.469 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 12:47:11.182 ServerApp] WebSocket ping timeout after 90000 ms.
[I 2022-07-01 12:47:16.183 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:1ec0f205-07ee-46bb-900d-e5b4faeee757
[W 2022-07-01 12:47:21.010 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 12:47:24.264 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 12:47:26.013 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
Task exception was never retrieved
future: <Task finished name='Task-59251' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59252' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59253' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59256' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59257' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59258' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59259' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59260' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59261' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59262' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59263' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59265' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59267' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59268' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59270' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59273' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59275' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59277' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59278' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59281' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59282' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59283' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59284' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59285' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59286' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59287' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59288' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59289' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59292' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59293' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59295' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59298' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59301' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59302' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59303' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59306' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59307' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59308' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59309' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59310' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59311' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59312' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59313' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59315' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59317' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59319' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59321' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59324' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59326' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59327' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59328' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59331' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59332' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59333' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59334' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59335' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59336' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59337' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59338' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59340' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59342' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59344' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59347' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59349' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59351' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59352' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59354' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59356' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59357' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59358' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59359' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
[W 2022-07-01 12:47:28.592 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 12:47:29.265 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[W 2022-07-01 12:47:34.715 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 12:47:39.716 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:f11e89d6-b160-4a1c-a022-30aa8f2dd73d
[W 2022-07-01 12:47:40.111 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 12:47:45.112 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:ff3d1dad-34e3-4e5c-a8a1-3d9ebfab0197
[W 2022-07-01 12:47:47.990 ServerApp] WebSocket ping timeout after 119997 ms.
[I 2022-07-01 12:47:52.993 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:72b7d9d2-b7fc-4ab6-bf96-7c264f456ed6
[I 2022-07-01 12:49:18.504 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:1ec0f205-07ee-46bb-900d-e5b4faeee757
[I 2022-07-01 12:49:18.510 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:ff3d1dad-34e3-4e5c-a8a1-3d9ebfab0197
[I 2022-07-01 12:49:18.511 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:72b7d9d2-b7fc-4ab6-bf96-7c264f456ed6
[I 2022-07-01 12:49:18.512 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 12:49:18.518 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:f11e89d6-b160-4a1c-a022-30aa8f2dd73d
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4b36d7c4-1360-40bd-bfc2-f2088697f961
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: eda2cfaa-fbfa-4569-b031-c65344331e15
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: b14d5a93-5d91-46cb-9830-6e9415bb75c8
[IPKernelApp] WARNING | No such comm: 49160e59-b46c-4c7d-8d97-159b58158a38
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 47a68195-8357-405c-9278-8adf68c45f83
[I 2022-07-01 12:49:35.387 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cc650a3d-cd9a-49f7-bf9e-efa857e7e68d
[I 2022-07-01 12:50:03.944 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:54:04.363 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 92834129-b138-4282-86e6-f9801388f6e5
[I 2022-07-01 12:54:57.645 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:f11e89d6-b160-4a1c-a022-30aa8f2dd73d
[I 2022-07-01 12:54:58.774 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:1ec0f205-07ee-46bb-900d-e5b4faeee757
[I 2022-07-01 12:54:59.732 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:ff3d1dad-34e3-4e5c-a8a1-3d9ebfab0197
[I 2022-07-01 12:56:04.812 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 12:58:05.277 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 13:04:32.061 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 13:09:06.936 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 13:15:07.492 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 13:17:08.193 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 947baa41-10a0-46b7-a345-39958d265274
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 1448d973-7a64-44b8-8c2a-fababb94bb3d
[I 2022-07-01 13:18:58.168 ServerApp] Kernel started: 16973f25-23f9-47ec-9a8d-dd5b6248f372
readline: /etc/inputrc: line 19: term: unknown variable name
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e39aaea2-f1b2-4e3c-8ae5-5333c54fa429
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 3cfdc78b-5467-4fda-a39b-ebc096a448d1
[W 2022-07-01 13:23:17.174 ServerApp] WebSocket ping timeout after 90000 ms.
[I 2022-07-01 13:23:22.175 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[W 2022-07-01 13:23:29.269 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:23:34.006 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 13:23:34.271 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[W 2022-07-01 13:23:35.388 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 13:23:39.008 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[W 2022-07-01 13:23:39.413 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 13:23:40.389 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:23:44.414 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[W 2022-07-01 13:23:48.513 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:23:48.514 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:23:52.371 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 13:23:53.514 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 13:23:53.516 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 13:23:57.372 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:25:26.606 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 13:25:26.611 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 13:25:26.613 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 13:25:26.615 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:25:26.615 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 13:25:26.616 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:25:26.626 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 13:25:26.627 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 867f37a9-b96f-4b82-ac14-65fc47cffb13
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: d25e6a6b-3e20-4592-bbac-f5182bbcbb44
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: c34cab3d-08b3-43e3-b6a3-94cca45f6810
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 142a4c47-3846-4b94-bbed-75b1d68a6ef8
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: b575efdb-d280-4278-a407-8bd66677920b
[IPKernelApp] WARNING | No such comm: 4aeb4af0-f00e-4056-bbbd-a4d86039df25
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 60f884ea-1322-464a-9be2-e1ad3963a66c
[W 2022-07-01 13:28:56.607 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:28:56.611 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:28:56.614 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:28:56.615 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:28:56.616 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:28:56.616 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:28:56.627 ServerApp] WebSocket ping timeout after 119997 ms.
[W 2022-07-01 13:28:56.628 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 13:29:01.608 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 13:29:01.612 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 13:29:01.614 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 13:29:01.615 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:29:01.617 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 13:29:01.617 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:29:01.627 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 13:29:01.629 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 13:32:28.994 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 13:32:29.011 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 13:32:29.012 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 13:32:29.012 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:32:29.013 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 13:32:29.014 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:32:29.017 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cd8e715a-4f72-4c18-bf4d-5b99f97c8c10
[I 2022-07-01 13:32:29.040 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 30ae5d45-6904-4629-954f-efec3b057081
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 69b702f3-ffc8-47c5-aeb6-4de3187ab506
[IPKernelApp] WARNING | No such comm: 8cb3e116-bc25-4fc6-b9e1-3b1faf2a701a
[IPKernelApp] WARNING | No such comm: 2e1ccba3-6bdb-4d04-ae85-6d8e41e4a68c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: a037b279-4ba1-4616-a236-aa89fc7dc0a5
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cfce7f60-280e-4677-8735-e94e03edbed7
[W 2022-07-01 13:46:58.995 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:46:59.012 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:46:59.012 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:46:59.013 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:46:59.014 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:46:59.014 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 13:46:59.018 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 13:46:59.040 ServerApp] WebSocket ping timeout after 119999 ms.
[I 2022-07-01 13:47:03.997 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 13:47:04.012 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 13:47:04.012 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 13:47:04.014 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:47:04.015 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 13:47:04.015 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:47:04.018 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 13:47:04.041 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 13:48:48.973 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 13:48:48.974 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 13:48:48.975 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 13:48:48.976 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 13:48:48.977 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 13:48:48.977 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 13:48:48.995 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 13:48:48.996 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 8e724f6f-0987-4fcf-b4c0-3ea09ad672a7
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: aba8bf47-6e3b-4655-a9ea-6ddba5350825
[IPKernelApp] WARNING | No such comm: 9d575f21-439f-442e-9fcf-9c9f02452666
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 911d0a2f-4f16-40b2-acab-e0dfb589824f
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 05065b34-0adc-41eb-a7ae-e3f3cd64215d
[IPKernelApp] WARNING | No such comm: 3aaf6faa-65ba-4167-af4c-989ee6c45aae
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: c7316c2a-819d-4fd7-8b7b-ad3a7c349909
[W 2022-07-01 14:04:48.973 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:04:48.975 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:04:48.975 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:04:48.976 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:04:48.978 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:04:48.978 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:04:48.997 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:04:48.997 ServerApp] WebSocket ping timeout after 119999 ms.
[I 2022-07-01 14:04:53.975 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:04:53.976 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:04:53.976 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:04:53.977 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:04:53.978 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:04:53.978 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:04:53.998 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 14:04:53.998 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 14:12:48.723 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:12:48.726 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:12:48.727 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:12:48.729 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:12:48.730 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:12:48.732 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:12:48.743 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 14:12:48.744 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 27264bd0-e44b-462e-b77f-95bb4476dd1d
[IPKernelApp] WARNING | No such comm: c3b7f9b5-a5fa-4b14-bc85-44533267bd7a
[IPKernelApp] WARNING | No such comm: 89c16a60-ab5a-4d7c-8168-45d55c9a621f
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 89bf15fb-2f91-43c3-978e-fd71fe546e08
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: c3e969ed-be06-4b6d-afa3-67cfbf308e64
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 875fcd7f-a8fb-4e8e-98dd-a7ab87cd6c47
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4dcb5598-c490-4a8b-803a-0dea8908cbbd
[W 2022-07-01 14:30:18.723 ServerApp] WebSocket ping timeout after 119997 ms.
[W 2022-07-01 14:30:18.727 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:30:18.728 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:30:18.729 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:30:18.730 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:30:18.733 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:30:18.744 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:30:18.744 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 14:30:23.724 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:30:23.728 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:30:23.729 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:30:23.730 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:30:23.732 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:30:23.733 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:30:23.744 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 14:30:23.744 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 14:31:58.713 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:31:58.719 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:31:58.728 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:31:58.730 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:31:58.732 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:31:58.733 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:31:58.733 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: ee9b3966-6a31-44ab-98e2-b20f5373407d
[I 2022-07-01 14:31:58.743 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 5337509d-33a1-4bc7-ab28-9bf6a6b8ecd1
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 637b242a-0577-4696-a7f3-b0837c9cbc6d
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 24d6f510-a96d-4ab0-8765-abaae1cea5fb
[IPKernelApp] WARNING | No such comm: bb24ad0b-596f-4fa8-94e1-3774821820b9
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e4cf1a5e-cc5a-4096-b5cc-817a35e2334f
[IPKernelApp] WARNING | No such comm: 2ce3455a-b3f3-400f-a3ca-f36fc91a3d7b
[W 2022-07-01 14:35:28.729 ServerApp] WebSocket ping timeout after 90000 ms.
[I 2022-07-01 14:35:33.730 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:35:54.997 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 241696cf-ebae-4a09-887a-a6c73c00c071
[W 2022-07-01 14:41:24.998 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:41:28.714 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:41:28.719 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:41:28.731 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:41:28.732 ServerApp] WebSocket ping timeout after 119998 ms.
[W 2022-07-01 14:41:28.733 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:41:28.734 ServerApp] WebSocket ping timeout after 119999 ms.
[W 2022-07-01 14:41:28.744 ServerApp] WebSocket ping timeout after 119998 ms.
[I 2022-07-01 14:41:29.999 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:41:33.715 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:41:33.720 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:41:33.732 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:41:33.733 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:41:33.734 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:41:33.734 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 14:41:33.744 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 14:51:06.051 ServerApp] Restoring connection for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:51:06.057 ServerApp] Restoring connection for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:51:06.058 ServerApp] Restoring connection for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:51:06.062 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 14:51:06.067 ServerApp] Restoring connection for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:51:06.067 ServerApp] Restoring connection for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:51:06.068 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 315c5873-2321-478c-a001-a294f58349c6
[I 2022-07-01 14:51:06.083 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 72ee4b46-ac6e-433a-a8dc-abbbe563a4f0
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: cbc8bfa4-dd04-48a3-a4ca-c3d6863e8524
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 131fcc64-4b00-4286-8955-dcbd93f10d94
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 2abefca2-a662-4648-98ca-c906d957dc07
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: fd5d5268-9b08-4b7b-8a2b-2d490a91450f
[IPKernelApp] WARNING | No such comm: c570dda0-a0e2-4807-9c40-dca5ec64c24f
[I 2022-07-01 14:51:27.178 ServerApp] Starting buffering for e42f0f13-06eb-482f-9f32-3548713185ab:fb0327c1-dd3c-4c71-8cd1-b56b4aaa22be
[I 2022-07-01 14:51:29.928 ServerApp] Starting buffering for 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d:a64fae89-d13a-47e8-a552-4c065b3142b6
[I 2022-07-01 14:51:32.565 ServerApp] Starting buffering for 16973f25-23f9-47ec-9a8d-dd5b6248f372:e05ac2df-f271-4ac8-b34e-0c578850361e
[I 2022-07-01 14:51:35.364 ServerApp] Starting buffering for 133cb437-381c-4f16-818b-45576f715f12:458ce216-b4cd-4f0f-bd9b-517e6b7af90e
[I 2022-07-01 14:51:36.346 ServerApp] Starting buffering for ef75afff-2fe6-4bdb-85e0-f8941f037171:a14e7350-c3c6-4fda-9062-2bcf615df174
[I 2022-07-01 14:52:00.217 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 14:54:00.932 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 14:56:01.509 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 14:58:02.084 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:00:02.654 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:02:03.116 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:04:03.587 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:06:04.043 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:08:04.503 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:10:04.988 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:12:05.473 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:14:05.959 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:16:06.410 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:18:06.903 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:20:07.380 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:22:07.875 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:24:08.387 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:26:08.891 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:28:09.367 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:30:09.931 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:32:10.579 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:36:11.051 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:38:11.514 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:40:12.003 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:42:12.394 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[W 2022-07-01 15:43:43.319 ServerApp] Replacing stale connection: a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 15:43:45.667 ServerApp] Starting buffering for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 15:43:45.667 ServerApp] Starting buffering for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[I 2022-07-01 15:43:45.668 ServerApp] Starting buffering for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[I 2022-07-01 15:43:45.668 ServerApp] Restoring connection for a806e594-9cdb-4c4a-aee4-4b4ea44aed17:ac03e03d-9d73-425b-85a3-f142bca5519e
[I 2022-07-01 15:43:49.664 ServerApp] Restoring connection for 9cf90e35-4179-438f-aa8a-9f3bd6af8d35:165021cd-5ad6-4428-bd7d-0fc6b9673a7c
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 20d6950a-ecd9-4cf0-91e3-cd9f5dc1b38a
[I 2022-07-01 15:43:52.349 ServerApp] Restoring connection for 0910d410-1877-4b92-9c57-96057a0eecfc:6d689c52-5e13-40ee-b73b-6f0c664a4f5b
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: d034b0a9-6fd7-4a58-bc88-352bf79f28f3
[I 2022-07-01 15:44:12.815 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:46:13.311 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[I 2022-07-01 15:48:10.408 ServerApp] Saving file at /m2_2022/sandbox/diag_one_obs.ipynb
[C 2022-07-01 15:49:49.401 ServerApp] received signal 15, stopping
Terminated
[I 2022-07-01 15:49:49.457 ServerApp] Shutting down 3 extensions
[I 2022-07-01 15:49:49.457 ServerApp] Shutting down 10 kernels
[I 2022-07-01 15:49:49.458 ServerApp] Kernel shutdown: 02ab2603-3f95-4942-86fb-59306979415e
[I 2022-07-01 15:49:49.458 ServerApp] Kernel shutdown: e42f0f13-06eb-482f-9f32-3548713185ab
[I 2022-07-01 15:49:49.458 ServerApp] Kernel shutdown: 9cf90e35-4179-438f-aa8a-9f3bd6af8d35
[I 2022-07-01 15:49:49.459 ServerApp] Kernel shutdown: 16973f25-23f9-47ec-9a8d-dd5b6248f372
[I 2022-07-01 15:49:49.459 ServerApp] Kernel shutdown: 2858f50d-722a-486d-acb6-524de679a197
[I 2022-07-01 15:49:49.459 ServerApp] Kernel shutdown: 0910d410-1877-4b92-9c57-96057a0eecfc
[I 2022-07-01 15:49:49.460 ServerApp] Kernel shutdown: 62ea1af6-ce30-45fb-8f3f-65d0f1d04e9d
[I 2022-07-01 15:49:49.460 ServerApp] Kernel shutdown: 133cb437-381c-4f16-818b-45576f715f12
[I 2022-07-01 15:49:49.460 ServerApp] Kernel shutdown: a806e594-9cdb-4c4a-aee4-4b4ea44aed17
[I 2022-07-01 15:49:49.460 ServerApp] Kernel shutdown: ef75afff-2fe6-4bdb-85e0-f8941f037171
[I 2022-07-01 15:49:52.278 ServerApp] Shutting down 0 terminals
Task exception was never retrieved
future: <Task finished name='Task-59360' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59361' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59362' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59363' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59364' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished name='Task-59365' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py:1100> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1102, in wrapper
    await fut
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 349, in __wakeup
    future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/asyncio/tasks.py", line 282, in __step
    result = coro.throw(exc)
  File "/home1/datahome/mdemol/.miniconda3/envs/m2env/lib/python3.8/site-packages/tornado/websocket.py", line 1104, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
